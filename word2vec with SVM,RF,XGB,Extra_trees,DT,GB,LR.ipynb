{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "463_2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9JV08eosMyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5644f9-6cf1-4370-b27d-48d8c3c972ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KaosE05Cbju"
      },
      "source": [
        "from keras.preprocessing import sequence, text\n",
        "from keras.models import Model\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv\n",
        "\n",
        "\n",
        "from sklearn import model_selection, naive_bayes, svm, ensemble, tree\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    classification_report as creport\n",
        ")\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8qI_9rKwDoT"
      },
      "source": [
        "# AraVec2.0: Pre-trained Arabic Word Embeddings model \n",
        "Source: https://github.com/bakrianoo/aravec/tree/master/AraVec%202.0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGfF1geNSzZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f130490-fdfd-4346-8a36-e26166f9c7a5"
      },
      "source": [
        "\"\"\"\n",
        "Citation:\n",
        "Abu Bakr Soliman, Kareem Eisa, and Samhaa R. El-Beltagy, “AraVec:\n",
        "A set of Arabic Word Embedding Models for use in Arabic NLP”,\n",
        "in proceedings of the 3rd International Conference on \n",
        "Arabic Computational Linguistics (ACLing 2017), Dubai, UAE, 2017.\n",
        "\"\"\"\n",
        "! unzip '/content/drive/MyDrive/tweets_sg_300.zip'  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/tweets_sg_300.zip\n",
            "  inflating: tweets_sg_300           \n",
            "  inflating: tweets_sg_300.trainables.syn1neg.npy  \n",
            "  inflating: tweets_sg_300.wv.vectors.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJLejALUS3w2"
      },
      "source": [
        "# Word_embedding_path\n",
        "embedding_path = '/content/tweets_sg_300'           #Twitter-Skipgram model-300d(trained on 77,600,000 Arabic tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z_xPhom6BiV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "a376731d-d137-470a-ac22-a976e12bf977"
      },
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>وزير الخارجية اللبناني جبران باسيل قال في سلسل...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>سورية بلد الحضارات تربطها بعلية او بحيوان</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اخي الحاج اذا شعرت انك محرجا من الانتقادات لتص...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ما فيك تعيش بلا ما تكب فتن ليل نهار وبكرة قلهم...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>هذا البطل الذي قاتل وجاذف بحياته لتحيا انت يا ...</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4671</th>\n",
              "      <td>كول هوا مرة تانيي وحلوا عن طيزو وطيزنا ومقلعين...</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4672</th>\n",
              "      <td>رئيس روحي؟ تروح روحك انت وكل مين شدّ عمشدّك مش...</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4673</th>\n",
              "      <td>إذا أرادت إسرائيل أن تضمن أمنها وهو حق عليها ا...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4674</th>\n",
              "      <td>خليك بحالك يا نعيمي على أساس أنت مش مرتزق و طب...</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4675</th>\n",
              "      <td>عيلة كتاب عدل من ثلاث اشقاء بالنتائج الاخيرة ه...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4676 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Tweet    Class\n",
              "0     وزير الخارجية اللبناني جبران باسيل قال في سلسل...   normal\n",
              "1             سورية بلد الحضارات تربطها بعلية او بحيوان   normal\n",
              "2     اخي الحاج اذا شعرت انك محرجا من الانتقادات لتص...   normal\n",
              "3     ما فيك تعيش بلا ما تكب فتن ليل نهار وبكرة قلهم...   normal\n",
              "4     هذا البطل الذي قاتل وجاذف بحياته لتحيا انت يا ...  abusive\n",
              "...                                                 ...      ...\n",
              "4671  كول هوا مرة تانيي وحلوا عن طيزو وطيزنا ومقلعين...  abusive\n",
              "4672  رئيس روحي؟ تروح روحك انت وكل مين شدّ عمشدّك مش...  abusive\n",
              "4673  إذا أرادت إسرائيل أن تضمن أمنها وهو حق عليها ا...   normal\n",
              "4674  خليك بحالك يا نعيمي على أساس أنت مش مرتزق و طب...  abusive\n",
              "4675  عيلة كتاب عدل من ثلاث اشقاء بالنتائج الاخيرة ه...   normal\n",
              "\n",
              "[4676 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDCeUyipOdAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbeef399-3a3a-45a7-adb6-ab96961abef0"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "for data_path in [\"/content/drive/MyDrive/OSACT4\"]:\n",
        "     with open(data_path, 'r') as f:\n",
        "          for i, line in enumerate(f):\n",
        "              if i == 0: continue\n",
        "              else:\n",
        "                  temp = line.split(',')\n",
        "                  X.append(temp[0].split())\n",
        "                  y.append(temp[1].replace('\\n', ''))\n",
        "X, y = np.array(X), np.array(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40LHaCN6AM7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f6eddb-eb1e-4b23-beb8-6be31d724f7a"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4676"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUeVuH2B0akw"
      },
      "source": [
        "## Get Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxim2tYsGQ3b"
      },
      "source": [
        "def get_init_parameters(path, ext=None):\n",
        "    word_model = KeyedVectors.load(path).wv\n",
        "    n_words = len(word_model.vocab)\n",
        "    vocab_dim = word_model[word_model.index2word[0]].shape[0]\n",
        "    index_dict = dict()\n",
        "    for i in range(n_words):\n",
        "        index_dict[word_model.index2word[i]] = i+1\n",
        "    print('Number of words in the word embedding',n_words)\n",
        "    #print('word_model', word_model)\n",
        "    #print(\"index_dict\",index_dict)\n",
        "    return word_model, index_dict, n_words, vocab_dim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll909TRTG0Yd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bae7ee-9f60-44be-a03a-579bb499c60a"
      },
      "source": [
        "WORD_MODEL, index_dict, MAX_FEATURES, EMBED_SIZE = get_init_parameters(embedding_path) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in the word embedding 331679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xaUdzMs0O_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b356cf91-4e93-45ec-ee21-fb01bc82aeeb"
      },
      "source": [
        "EMBED_SIZE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt-j40bMG6U3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5258f35e-183f-4277-d745-677c38b6d50c"
      },
      "source": [
        "len(index_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "331679"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZKwTnzYJUxX"
      },
      "source": [
        "def get_word_index(train_raw_text, test_raw_text, n_words):\n",
        "    tokenizer = text.Tokenizer(num_words=n_words)\n",
        "    tokenizer.fit_on_texts(list(train_raw_text))\n",
        "    word_index = tokenizer.word_index\n",
        "\n",
        "    return word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjKUjdz7CJ6m"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aPXVJqTJhjY"
      },
      "source": [
        " word_index  = get_word_index(X,X_test,MAX_FEATURES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzJ2fELYG8wc"
      },
      "source": [
        "def w2v(word_index, embedding_index, vocab_dim):\n",
        "    print('Building embedding matrix...')\n",
        "    dicc={}\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, vocab_dim))\n",
        "    for word, i in word_index.items():\n",
        "        try:\n",
        "            embedding_matrix[i] = embedding_index.get_vector(word)\n",
        "        except:\n",
        "            pass\n",
        "        dicc[word]= embedding_matrix[i]\n",
        "\n",
        "    print('Embedding matrix built.') \n",
        "    #print(\"Word index\", word_index.items())\n",
        "    #print(embedding_matrix) \n",
        "    return dicc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPuD1ZC-IRa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bd24a7-e7e0-4739-d427-fe7d39f8ee36"
      },
      "source": [
        "dicc= w2v(word_index, WORD_MODEL, EMBED_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building embedding matrix...\n",
            "Embedding matrix built.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgMBeUP2IXqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498eac3d-ee49-4616-b3a6-28cf106664c8"
      },
      "source": [
        "len(dicc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOZzXhcrL1X_"
      },
      "source": [
        "\"\"\"\n",
        "To use AraVec2.0 with the classical machine learning models, \n",
        "the average vector of all the embeddings of the tweet words is computed\n",
        "\"\"\"\n",
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, dicc):\n",
        "        self.dicc = dicc\n",
        "        if len(dicc)>0:\n",
        "            self.dim=300\n",
        "        else:\n",
        "            self.dim=0\n",
        "            \n",
        "    def fit(self, X, y):\n",
        "        return self \n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([self.dicc[w] for w in words if w in self.dicc] \n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brnQ7H9HziTC"
      },
      "source": [
        "# Word Embeddings\n",
        "\n",
        "We experimented with various classical machine learning models:\n",
        "\n",
        "1.  SVM\n",
        "2.  Random Forest\n",
        "3.  XGBoost\n",
        "4.  Extra Trees\n",
        "5.  Decision Trees\n",
        "6.  Gradient Boosting\n",
        "7.  Logistic Regression\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na0qajnmi_cO"
      },
      "source": [
        "## 1. SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KjSnDNRM6S9"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "svm_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"svm_w2v\",  svm.SVC())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i99LwyULNb15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb45502c-3a57-470b-8350-fa4f9a0f5426"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "svm_w2v= svm_w2v.fit(X_train,y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 5.26 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVJ0S5VLN43m"
      },
      "source": [
        "predictions_SVM = svm_w2v.predict(X_test)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3w1RXyKNyc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b87acb-6635-4c64-eb91-1dff8fbaf9ad"
      },
      "source": [
        "print(\"SVM macro-averaged F1-score -> \", f1_score(y_test, predictions_SVM,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM macro-averaged F1-score ->  0.5647011772266355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf8L4BrjajWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52838d65-e7eb-4dd8-fbab-c77b0d0b800b"
      },
      "source": [
        "print(creport(y_test, predictions_SVM,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.7269    0.6250    0.6721       264\n",
            "     abusive     0.7143    0.0769    0.1389        65\n",
            "        hate     0.8234    0.9522    0.8831       607\n",
            "\n",
            "    accuracy                         0.7991       936\n",
            "   macro avg     0.7548    0.5514    0.5647       936\n",
            "weighted avg     0.7886    0.7991    0.7719       936\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrRNNriMjDUl"
      },
      "source": [
        "## 2. RandomForest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkslR7NdWtAv"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "RF_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"RF\",   ensemble.RandomForestClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf8PN0bqXrb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4dec620-eb2e-463a-e201-4b43f9a6c3ff"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "RF_w2v= RF_w2v.fit(X_train,y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 5.33 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCpiwQeLX5EN"
      },
      "source": [
        "predictions_RF = RF_w2v.predict(X_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4s_066QYFqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a658c411-d899-4cfe-b9d6-4240b04352f4"
      },
      "source": [
        "print(\"RF macro-averaged F1-score -> \",f1_score(y_test, predictions_RF,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RF macro-averaged F1-score ->  0.47154880163986124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMHSpD7ea-nO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d40b41-835e-4bfe-c20f-6b709412c1c1"
      },
      "source": [
        "print(creport(y_test, predictions_RF,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.6902    0.4811    0.5670       264\n",
            "     abusive     0.0000    0.0000    0.0000        65\n",
            "        hate     0.7660    0.9489    0.8477       607\n",
            "\n",
            "    accuracy                         0.7511       936\n",
            "   macro avg     0.4854    0.4767    0.4715       936\n",
            "weighted avg     0.6914    0.7511    0.7096       936\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN3_to_DjI6H"
      },
      "source": [
        "## 3. XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrSYbcoTZMgR"
      },
      "source": [
        "XGB_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"XGB\",   XGBClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlBqVF-AaD_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed47f549-1827-43d1-e7b1-b704ff5aac2b"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "XGB_w2v= XGB_w2v.fit(X_train, y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 22.43 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3w1QyeGajmU"
      },
      "source": [
        "predictions_XGB = XGB_w2v.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1AVNnIEaqRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b18c4d-aec7-48a6-c336-608439e309ea"
      },
      "source": [
        "print(\"XGB macro-averaged F1-score -> \", f1_score(y_test, predictions_XGB,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGB macro-averaged F1-score ->  0.5475709399821543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WboiSlq5bLI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48223723-8327-4063-96eb-c176c72b2201"
      },
      "source": [
        "print(creport(y_test, predictions_XGB,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.7018    0.5795    0.6349       264\n",
            "     abusive     0.5000    0.0769    0.1333        65\n",
            "        hate     0.8121    0.9473    0.8745       607\n",
            "\n",
            "    accuracy                         0.7831       936\n",
            "   macro avg     0.6713    0.5346    0.5476       936\n",
            "weighted avg     0.7594    0.7831    0.7555       936\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqhcGuV2jNhx"
      },
      "source": [
        "## 4. ExtraTrees Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI5G0KYAa3k5"
      },
      "source": [
        "extraTrees_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"extraTrees\",   ensemble.ExtraTreesClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpDyQd8rbItU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f9f7fc-c972-40fd-f5be-52d9e9aedd5c"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "extraTrees_w2v= extraTrees_w2v.fit(X_train,y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 1.43 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQrLHKWfbN0q"
      },
      "source": [
        "predictions_extraTrees= extraTrees_w2v.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW7Fv42CbMx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b011b738-0187-4ab8-8b15-b024400a5331"
      },
      "source": [
        "print(\"ExtraTreesClassifier macro-averaged F1-score -> \",f1_score(y_test, predictions_extraTrees,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ExtraTreesClassifier macro-averaged F1-score ->  0.46720500430353845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp7ydxZlbTrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ade8c04-5c16-4d72-9cb9-b6c231c41d9b"
      },
      "source": [
        "print(creport(y_test, predictions_extraTrees,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.7256    0.4508    0.5561       264\n",
            "     abusive     0.0000    0.0000    0.0000        65\n",
            "        hate     0.7552    0.9605    0.8455       607\n",
            "\n",
            "    accuracy                         0.7500       936\n",
            "   macro avg     0.4936    0.4704    0.4672       936\n",
            "weighted avg     0.6944    0.7500    0.7052       936\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4pnFoW7jSt-"
      },
      "source": [
        "## 5. GradientBoosting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOjR-FRvbVcn"
      },
      "source": [
        "GB_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"GradientBoostingClassifier\",   ensemble.GradientBoostingClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YCBoV4Kbi2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d78566-aebd-438f-95a7-b48ed76d3289"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "GB_w2v= GB_w2v.fit(X_train,y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 122.7 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vf5dj84bsL7"
      },
      "source": [
        "predictions_GB= GB_w2v.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYu2v0Viby85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f630aca0-da28-4c69-9336-8bb491ab3b43"
      },
      "source": [
        "print(\"GradientBoostingClassifier macro-averaged F1-score -> \", f1_score(y_test, predictions_GB,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GradientBoostingClassifier macro-averaged F1-score ->  0.5727337832852275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_LTy6FcbfdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df949a04-43cb-4304-d8c7-c06bd620cba9"
      },
      "source": [
        "print(creport(y_test, predictions_GB,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.6824    0.6023    0.6398       264\n",
            "     abusive     0.6667    0.1231    0.2078        65\n",
            "        hate     0.8177    0.9308    0.8706       607\n",
            "\n",
            "    accuracy                         0.7821       936\n",
            "   macro avg     0.7222    0.5521    0.5727       936\n",
            "weighted avg     0.7690    0.7821    0.7595       936\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIuek633jV02"
      },
      "source": [
        "## 6. DecisionTree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unFouJK8b3ft"
      },
      "source": [
        "DT_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"DT\",   tree.DecisionTreeClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5AYQewqdru_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0c6460-b162-4a8e-ac4c-76c80ee30d25"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "DT_w2v= DT_w2v.fit(X_train,y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 1.59 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlmFoZhjdv1g"
      },
      "source": [
        "predictions_DT= DT_w2v.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wE2l2MUh70G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d211afa0-a53f-4794-f0ed-b33adf2af429"
      },
      "source": [
        "print(\"DecisionTreeClassifier macro-averaged F1-score -> \",f1_score(y_test, predictions_DT,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier macro-averaged F1-score ->  0.42776292503333097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IleuQj8Rbq8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a138250-1976-475e-f17b-391f75205a13"
      },
      "source": [
        "print(creport(y_test, predictions_DT,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.4225    0.4545    0.4380       264\n",
            "     abusive     0.1039    0.1231    0.1127        65\n",
            "        hate     0.7530    0.7133    0.7327       607\n",
            "\n",
            "    accuracy                         0.5994       936\n",
            "   macro avg     0.4265    0.4303    0.4278       936\n",
            "weighted avg     0.6147    0.5994    0.6065       936\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sICjS3UbGnBY"
      },
      "source": [
        "## 7. Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUrCDiZYGrnv"
      },
      "source": [
        "from sklearn import linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_DI9PdFiI1J"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "LR_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"LR_w2v\",  linear_model.LogisticRegression(multi_class='multinomial'))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfveJk30igEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c166f1-aae9-4d25-d5d5-b99804f1cdd5"
      },
      "source": [
        "LR_w2v= LR_w2v.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZdgPw0foMsG"
      },
      "source": [
        "predictions_LR= LR_w2v.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgFam4fLoRnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d20819cc-07be-4cd4-8baa-16a36cbb763e"
      },
      "source": [
        "print(\"DecisionTreeClassifier macro-averaged F1-score -> \", f1_score(y_test, predictions_LR,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier macro-averaged F1-score ->  0.5561613014884044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "968xocrMc6SS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7fd91f-c148-41ef-d0a0-12556e5c04df"
      },
      "source": [
        "print(creport(y_test, predictions_LR,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.6708    0.6098    0.6389       264\n",
            "     abusive     0.3684    0.1077    0.1667        65\n",
            "        hate     0.8183    0.9127    0.8629       607\n",
            "\n",
            "    accuracy                         0.7714       936\n",
            "   macro avg     0.6192    0.5434    0.5562       936\n",
            "weighted avg     0.7455    0.7714    0.7514       936\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}