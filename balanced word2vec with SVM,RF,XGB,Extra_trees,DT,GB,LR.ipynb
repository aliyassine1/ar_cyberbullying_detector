{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "463_2 Balanced",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmX9A6cJojiA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9JV08eosMyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6847718a-1794-4770-deed-e4ee374d9ba3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KaosE05Cbju"
      },
      "source": [
        "from keras.preprocessing import sequence, text\n",
        "from keras.models import Model\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv\n",
        "\n",
        "\n",
        "from sklearn import model_selection, naive_bayes, svm, ensemble, tree\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    classification_report as creport\n",
        ")\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8qI_9rKwDoT"
      },
      "source": [
        "# AraVec2.0: Pre-trained Arabic Word Embeddings model \n",
        "Source: https://github.com/bakrianoo/aravec/tree/master/AraVec%202.0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGfF1geNSzZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ed5b96-edf2-4e0b-85eb-aa15b7329f9e"
      },
      "source": [
        "\"\"\"\n",
        "Citation:\n",
        "Abu Bakr Soliman, Kareem Eisa, and Samhaa R. El-Beltagy, “AraVec:\n",
        "A set of Arabic Word Embedding Models for use in Arabic NLP”,\n",
        "in proceedings of the 3rd International Conference on \n",
        "Arabic Computational Linguistics (ACLing 2017), Dubai, UAE, 2017.\n",
        "\"\"\"\n",
        "! unzip '/content/drive/MyDrive/tweets_sg_300.zip'  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/tweets_sg_300.zip\n",
            "  inflating: tweets_sg_300           \n",
            "  inflating: tweets_sg_300.trainables.syn1neg.npy  \n",
            "  inflating: tweets_sg_300.wv.vectors.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJLejALUS3w2"
      },
      "source": [
        "# Word_embedding_path\n",
        "embedding_path = '/content/tweets_sg_300'           #Twitter-Skipgram model-300d(trained on 77,600,000 Arabic tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z_xPhom6BiV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "a97c9ac1-84eb-427d-c28f-6cf0e5adde6a"
      },
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/Updated_Dataset.csv')\n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>وسخ وليس وصخ هاه مين الوسخ فينا يا نجم ...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>لا تحسبوني نسيتكم يا عبنده يا كويحة يا م...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>تحرير فلسطين اله رجاله ، وانتوا يا نسل ال...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>يا لبناني يا فضلات الاستعمار الفرنسي اللب...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الخيانه والغدر والعماله من خصالكم نحن من ح...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2514</th>\n",
              "      <td>يلي لهلا مو عرفان هاد يا اجدب يا اما عم يجدبها</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2515</th>\n",
              "      <td>يمثل تحفة الفن والعمارة القوطية ويعد من المعال...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2516</th>\n",
              "      <td>يمكن   لو  كان  ابوك  مربيك  وضاربك  شي  كفين ...</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2517</th>\n",
              "      <td>يهودي منهم وفيهم</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2518</th>\n",
              "      <td>ئوبة كلاب خربوها وقعدوا على تلتها</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2519 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Tweet    Class\n",
              "0            وسخ وليس وصخ هاه مين الوسخ فينا يا نجم ...     hate\n",
              "1           لا تحسبوني نسيتكم يا عبنده يا كويحة يا م...     hate\n",
              "2          تحرير فلسطين اله رجاله ، وانتوا يا نسل ال...     hate\n",
              "3          يا لبناني يا فضلات الاستعمار الفرنسي اللب...     hate\n",
              "4         الخيانه والغدر والعماله من خصالكم نحن من ح...     hate\n",
              "...                                                 ...      ...\n",
              "2514     يلي لهلا مو عرفان هاد يا اجدب يا اما عم يجدبها  abusive\n",
              "2515  يمثل تحفة الفن والعمارة القوطية ويعد من المعال...     hate\n",
              "2516  يمكن   لو  كان  ابوك  مربيك  وضاربك  شي  كفين ...  abusive\n",
              "2517                                   يهودي منهم وفيهم   normal\n",
              "2518                  ئوبة كلاب خربوها وقعدوا على تلتها     hate\n",
              "\n",
              "[2519 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDCeUyipOdAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8e71e9-5e34-4990-f224-9d003095e53b"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "for data_path in [\"/content/drive/MyDrive/OSACT4\"]:\n",
        "     with open(data_path, 'r') as f:\n",
        "          for i, line in enumerate(f):\n",
        "              if i == 0: continue\n",
        "              else:\n",
        "                  temp = line.split(',')\n",
        "                  X.append(temp[0].split())\n",
        "                  y.append(temp[1].replace('\\n', ''))\n",
        "X, y = np.array(X), np.array(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40LHaCN6AM7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c839c6-a69c-4a2d-d474-88a9087a2ae1"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUeVuH2B0akw"
      },
      "source": [
        "## Get Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxim2tYsGQ3b"
      },
      "source": [
        "def get_init_parameters(path, ext=None):\n",
        "    word_model = KeyedVectors.load(path).wv\n",
        "    n_words = len(word_model.vocab)\n",
        "    vocab_dim = word_model[word_model.index2word[0]].shape[0]\n",
        "    index_dict = dict()\n",
        "    for i in range(n_words):\n",
        "        index_dict[word_model.index2word[i]] = i+1\n",
        "    print('Number of words in the word embedding',n_words)\n",
        "    #print('word_model', word_model)\n",
        "    #print(\"index_dict\",index_dict)\n",
        "    return word_model, index_dict, n_words, vocab_dim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll909TRTG0Yd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45da9357-6072-49d6-95bf-a0e9af4c3959"
      },
      "source": [
        "WORD_MODEL, index_dict, MAX_FEATURES, EMBED_SIZE = get_init_parameters(embedding_path) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in the word embedding 331679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xaUdzMs0O_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45127dde-45a3-42ae-d493-c873574feb1d"
      },
      "source": [
        "EMBED_SIZE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt-j40bMG6U3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fb6955b-6662-4545-9c4c-8320d015b110"
      },
      "source": [
        "len(index_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "331679"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZKwTnzYJUxX"
      },
      "source": [
        "def get_word_index(train_raw_text, test_raw_text, n_words):\n",
        "    tokenizer = text.Tokenizer(num_words=n_words)\n",
        "    tokenizer.fit_on_texts(list(train_raw_text))\n",
        "    word_index = tokenizer.word_index\n",
        "\n",
        "    return word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjKUjdz7CJ6m"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aPXVJqTJhjY"
      },
      "source": [
        " word_index  = get_word_index(X,X_test,MAX_FEATURES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzJ2fELYG8wc"
      },
      "source": [
        "def w2v(word_index, embedding_index, vocab_dim):\n",
        "    print('Building embedding matrix...')\n",
        "    dicc={}\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, vocab_dim))\n",
        "    for word, i in word_index.items():\n",
        "        try:\n",
        "            embedding_matrix[i] = embedding_index.get_vector(word)\n",
        "        except:\n",
        "            pass\n",
        "        dicc[word]= embedding_matrix[i]\n",
        "\n",
        "    print('Embedding matrix built.') \n",
        "    #print(\"Word index\", word_index.items())\n",
        "    #print(embedding_matrix) \n",
        "    return dicc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPuD1ZC-IRa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0685a84-1e2e-4f26-945b-2aff5a74e332"
      },
      "source": [
        "dicc= w2v(word_index, WORD_MODEL, EMBED_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building embedding matrix...\n",
            "Embedding matrix built.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgMBeUP2IXqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62edfab-a52f-4bb4-bb63-cb6ecb1dc87a"
      },
      "source": [
        "len(dicc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOZzXhcrL1X_"
      },
      "source": [
        "\"\"\"\n",
        "To use AraVec2.0 with the classical machine learning models, \n",
        "the average vector of all the embeddings of the tweet words is computed\n",
        "\"\"\"\n",
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, dicc):\n",
        "        self.dicc = dicc\n",
        "        if len(dicc)>0:\n",
        "            self.dim=300\n",
        "        else:\n",
        "            self.dim=0\n",
        "            \n",
        "    def fit(self, X, y):\n",
        "        return self \n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([self.dicc[w] for w in words if w in self.dicc] \n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brnQ7H9HziTC"
      },
      "source": [
        "# Word Embeddings\n",
        "\n",
        "We experimented with various classical machine learning models:\n",
        "\n",
        "1.  SVM\n",
        "2.  Random Forest\n",
        "3.  XGBoost\n",
        "4.  Extra Trees\n",
        "5.  Decision Trees\n",
        "6.  Gradient Boosting\n",
        "7.  Logistic Regression\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na0qajnmi_cO"
      },
      "source": [
        "## 1. SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KjSnDNRM6S9"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "svm_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"svm_w2v\",  svm.SVC())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i99LwyULNb15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd59c2fb-6f53-42ff-d073-6fb4ff56739c"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "svm_w2v= svm_w2v.fit(X_train,y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 1.43 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVJ0S5VLN43m"
      },
      "source": [
        "predictions_SVM = svm_w2v.predict(X_test)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3w1RXyKNyc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af18c551-0971-4a7e-c504-654a17fd69d0"
      },
      "source": [
        "print(\"SVM macro-averaged F1-score -> \", f1_score(y_test, predictions_SVM,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM macro-averaged F1-score ->  0.7261077027948194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf8L4BrjajWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e39e654-e29f-4dc6-e2e0-e048c1fb02e4"
      },
      "source": [
        "print(creport(y_test, predictions_SVM,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.6746    0.6590    0.6667       173\n",
            "     abusive     0.7117    0.7117    0.7117       163\n",
            "        hate     0.7907    0.8095    0.8000       168\n",
            "\n",
            "    accuracy                         0.7262       504\n",
            "   macro avg     0.7256    0.7267    0.7261       504\n",
            "weighted avg     0.7253    0.7262    0.7257       504\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrRNNriMjDUl"
      },
      "source": [
        "## 2. RandomForest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkslR7NdWtAv"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "RF_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"RF\",   ensemble.RandomForestClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf8PN0bqXrb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871ec10c-bccb-4e76-d734-474bba21d170"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "RF_w2v= RF_w2v.fit(X_train,y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 2.32 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCpiwQeLX5EN"
      },
      "source": [
        "predictions_RF = RF_w2v.predict(X_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4s_066QYFqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95df1d9a-9dcf-410c-d0f1-a748fae357ec"
      },
      "source": [
        "print(\"RF macro-averaged F1-score -> \",f1_score(y_test, predictions_RF,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RF macro-averaged F1-score ->  0.6780679968690867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMHSpD7ea-nO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b63cfd3-c4c0-4aaf-9721-c619dc9e2be5"
      },
      "source": [
        "print(creport(y_test, predictions_RF,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.5979    0.6705    0.6322       173\n",
            "     abusive     0.7172    0.6380    0.6753       163\n",
            "        hate     0.7333    0.7202    0.7267       168\n",
            "\n",
            "    accuracy                         0.6766       504\n",
            "   macro avg     0.6828    0.6763    0.6781       504\n",
            "weighted avg     0.6817    0.6766    0.6776       504\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN3_to_DjI6H"
      },
      "source": [
        "## 3. XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrSYbcoTZMgR"
      },
      "source": [
        "XGB_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"XGB\",   XGBClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlBqVF-AaD_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81ed940-d52c-4a72-ba29-373c101c1edb"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "XGB_w2v= XGB_w2v.fit(X_train, y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 12.25 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3w1QyeGajmU"
      },
      "source": [
        "predictions_XGB = XGB_w2v.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1AVNnIEaqRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71ff776a-6854-45fa-9dfe-65e7a35284cc"
      },
      "source": [
        "print(\"XGB macro-averaged F1-score -> \", f1_score(y_test, predictions_XGB,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGB macro-averaged F1-score ->  0.7080182354518637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WboiSlq5bLI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc69878f-a5de-4504-f464-4f7dba5678c1"
      },
      "source": [
        "print(creport(y_test, predictions_XGB,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.6687    0.6416    0.6549       173\n",
            "     abusive     0.6647    0.6810    0.6727       163\n",
            "        hate     0.7895    0.8036    0.7965       168\n",
            "\n",
            "    accuracy                         0.7083       504\n",
            "   macro avg     0.7076    0.7087    0.7080       504\n",
            "weighted avg     0.7076    0.7083    0.7078       504\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqhcGuV2jNhx"
      },
      "source": [
        "## 4. ExtraTrees Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI5G0KYAa3k5"
      },
      "source": [
        "extraTrees_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"extraTrees\",   ensemble.ExtraTreesClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpDyQd8rbItU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ce77fb-3456-41d2-dda8-a987f6ba1ff3"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "extraTrees_w2v= extraTrees_w2v.fit(X_train,y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 0.75 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQrLHKWfbN0q"
      },
      "source": [
        "predictions_extraTrees= extraTrees_w2v.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW7Fv42CbMx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7639efea-c93a-4ae0-81c0-41f690efe11b"
      },
      "source": [
        "print(\"ExtraTreesClassifier macro-averaged F1-score -> \",f1_score(y_test, predictions_extraTrees,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ExtraTreesClassifier macro-averaged F1-score ->  0.6811020014807546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp7ydxZlbTrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c8bd4b-448e-4bb7-cae9-0bdc23447949"
      },
      "source": [
        "print(creport(y_test, predictions_extraTrees,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.6163    0.6127    0.6145       173\n",
            "     abusive     0.6606    0.6687    0.6646       163\n",
            "        hate     0.7665    0.7619    0.7642       168\n",
            "\n",
            "    accuracy                         0.6806       504\n",
            "   macro avg     0.6811    0.6811    0.6811       504\n",
            "weighted avg     0.6807    0.6806    0.6806       504\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4pnFoW7jSt-"
      },
      "source": [
        "## 5. GradientBoosting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOjR-FRvbVcn"
      },
      "source": [
        "GB_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"GradientBoostingClassifier\",   ensemble.GradientBoostingClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YCBoV4Kbi2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f872dc-2c5d-4ca4-b3a8-2d6529b0cd2a"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "GB_w2v= GB_w2v.fit(X_train,y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 52.24 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vf5dj84bsL7"
      },
      "source": [
        "predictions_GB= GB_w2v.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYu2v0Viby85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce186590-30e8-4b99-b407-8ce696bb7d25"
      },
      "source": [
        "print(\"GradientBoostingClassifier macro-averaged F1-score -> \", f1_score(y_test, predictions_GB,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GradientBoostingClassifier macro-averaged F1-score ->  0.6944927536231883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_LTy6FcbfdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4b5660-fddf-47b0-b7c5-58034ba14808"
      },
      "source": [
        "print(creport(y_test, predictions_GB,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.6453    0.6416    0.6435       173\n",
            "     abusive     0.6728    0.6687    0.6708       163\n",
            "        hate     0.7647    0.7738    0.7692       168\n",
            "\n",
            "    accuracy                         0.6944       504\n",
            "   macro avg     0.6943    0.6947    0.6945       504\n",
            "weighted avg     0.6940    0.6944    0.6942       504\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIuek633jV02"
      },
      "source": [
        "## 6. DecisionTree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unFouJK8b3ft"
      },
      "source": [
        "DT_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"DT\",   tree.DecisionTreeClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5AYQewqdru_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a56418af-9300-4caa-d89d-264cffbeb671"
      },
      "source": [
        "time_start = time()\n",
        "\n",
        "DT_w2v= DT_w2v.fit(X_train,y_train)\n",
        "\n",
        "time_start = time() - time_start\n",
        "\n",
        "print(\"Took : \"+str(np.round(time_start, 2))+\" (s)\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took : 0.75 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlmFoZhjdv1g"
      },
      "source": [
        "predictions_DT= DT_w2v.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wE2l2MUh70G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3710df3-fa12-4a74-c553-4ba71e80b251"
      },
      "source": [
        "print(\"DecisionTreeClassifier macro-averaged F1-score -> \",f1_score(y_test, predictions_DT,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier macro-averaged F1-score ->  0.4722745632956901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IleuQj8Rbq8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598b9ed6-b978-4341-ff00-df7d719b7de8"
      },
      "source": [
        "print(creport(y_test, predictions_DT,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.4688    0.4335    0.4505       173\n",
            "     abusive     0.4427    0.5215    0.4789       163\n",
            "        hate     0.5132    0.4643    0.4875       168\n",
            "\n",
            "    accuracy                         0.4722       504\n",
            "   macro avg     0.4749    0.4731    0.4723       504\n",
            "weighted avg     0.4751    0.4722    0.4720       504\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sICjS3UbGnBY"
      },
      "source": [
        "## 7. Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUrCDiZYGrnv"
      },
      "source": [
        "from sklearn import linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_DI9PdFiI1J"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "LR_w2v = Pipeline([\n",
        "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(dicc)),\n",
        "    (\"LR_w2v\",  linear_model.LogisticRegression(multi_class='multinomial'))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfveJk30igEm"
      },
      "source": [
        "LR_w2v= LR_w2v.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZdgPw0foMsG"
      },
      "source": [
        "predictions_LR= LR_w2v.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgFam4fLoRnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c1ce553-4284-4196-83d2-891d21d42695"
      },
      "source": [
        "print(\"DecisionTreeClassifier macro-averaged F1-score -> \", f1_score(y_test, predictions_LR,average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier macro-averaged F1-score ->  0.7059934535047657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "968xocrMc6SS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf6361d-ffed-4fd2-bac2-d0504a9c7d1a"
      },
      "source": [
        "print(creport(y_test, predictions_LR,target_names=[\"normal\", \"abusive\", \"hate\"],digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.6788    0.6474    0.6627       173\n",
            "     abusive     0.6707    0.6871    0.6788       163\n",
            "        hate     0.7674    0.7857    0.7765       168\n",
            "\n",
            "    accuracy                         0.7063       504\n",
            "   macro avg     0.7056    0.7067    0.7060       504\n",
            "weighted avg     0.7057    0.7063    0.7058       504\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}